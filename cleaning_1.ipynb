{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize \n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data \n",
    "\n",
    "Import json files and convert to dataframe\n",
    "\n",
    "** better to use json.load or pandas.read_json?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file = open('/opendota api constants/heroes.json')\n",
    "# hero_id = json.load(input_file)\n",
    "# input_file.close()\n",
    "# print('hero_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cleaning with starladder data \n",
    "\n",
    "input_file = open('matches/league_id_10979_starladder_s2_matchdata.json') \n",
    "data = json.load(input_file)\n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_json('matches/league_id_10979_starladder_s2_matchdata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning:\n",
      "\n",
      "pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "big_df = json_normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe for match results\n",
    "\n",
    "This will cover general id columns and basic match results such as match id, league id, dire/radiant teams, and if radiant won"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1: since data is saved as json, use pd.read_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>barracks_status_dire</th>\n",
       "      <th>barracks_status_radiant</th>\n",
       "      <th>chat</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cosmetics</th>\n",
       "      <th>dire_score</th>\n",
       "      <th>dire_team_id</th>\n",
       "      <th>draft_timings</th>\n",
       "      <th>duration</th>\n",
       "      <th>engine</th>\n",
       "      <th>first_blood_time</th>\n",
       "      <th>game_mode</th>\n",
       "      <th>human_players</th>\n",
       "      <th>leagueid</th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>match_seq_num</th>\n",
       "      <th>negative_votes</th>\n",
       "      <th>objectives</th>\n",
       "      <th>picks_bans</th>\n",
       "      <th>positive_votes</th>\n",
       "      <th>radiant_gold_adv</th>\n",
       "      <th>radiant_score</th>\n",
       "      <th>radiant_team_id</th>\n",
       "      <th>radiant_win</th>\n",
       "      <th>radiant_xp_adv</th>\n",
       "      <th>skill</th>\n",
       "      <th>start_time</th>\n",
       "      <th>teamfights</th>\n",
       "      <th>tower_status_dire</th>\n",
       "      <th>tower_status_radiant</th>\n",
       "      <th>version</th>\n",
       "      <th>replay_salt</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_type</th>\n",
       "      <th>league</th>\n",
       "      <th>radiant_team</th>\n",
       "      <th>dire_team</th>\n",
       "      <th>players</th>\n",
       "      <th>patch</th>\n",
       "      <th>all_word_counts</th>\n",
       "      <th>my_word_counts</th>\n",
       "      <th>throw</th>\n",
       "      <th>loss</th>\n",
       "      <th>replay_url</th>\n",
       "      <th>region</th>\n",
       "      <th>comeback</th>\n",
       "      <th>stomp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4968150000</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>[{'time': -960, 'type': 'chatwheel', 'key': '1...</td>\n",
       "      <td>308</td>\n",
       "      <td>{'647': 130, '4670': 130, '4794': 4, '5181': 1...</td>\n",
       "      <td>42</td>\n",
       "      <td>36.0</td>\n",
       "      <td>[{'order': 1, 'pick': False, 'active_team': 2,...</td>\n",
       "      <td>4934</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10749</td>\n",
       "      <td>1</td>\n",
       "      <td>4167421134</td>\n",
       "      <td>369</td>\n",
       "      <td>[{'time': 29, 'type': 'CHAT_MESSAGE_FIRSTBLOOD...</td>\n",
       "      <td>[{'is_pick': False, 'hero_id': 106, 'team': 1,...</td>\n",
       "      <td>4918</td>\n",
       "      <td>[0, 495, 762, 808, 878, 1145, 2106, 2059, 2167...</td>\n",
       "      <td>54</td>\n",
       "      <td>39.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0, 394, 247, 561, 224, 839, 1582, 1728, 1771,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-08-15 11:20:48</td>\n",
       "      <td>[{'start': 915, 'end': 959, 'last_death': 944,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1796</td>\n",
       "      <td>21</td>\n",
       "      <td>37509985</td>\n",
       "      <td>358264</td>\n",
       "      <td>1</td>\n",
       "      <td>{'leagueid': 10749, 'ticket': None, 'banner': ...</td>\n",
       "      <td>{'team_id': 39, 'name': 'Evil Geniuses', 'tag'...</td>\n",
       "      <td>{'team_id': 36, 'name': 'Natus Vincere', 'tag'...</td>\n",
       "      <td>[{'match_id': 4968150000, 'player_slot': 0, 'a...</td>\n",
       "      <td>41</td>\n",
       "      <td>{'gl': 1, 'hf': 1, 'gg': 5, 'wp': 1}</td>\n",
       "      <td>{}</td>\n",
       "      <td>9155.0</td>\n",
       "      <td>18713.0</td>\n",
       "      <td>http://replay308.valve.net/570/4968150000_3750...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     match_id  barracks_status_dire  barracks_status_radiant  \\\n",
       "0  4968150000                     0                       63   \n",
       "\n",
       "                                                chat  cluster  \\\n",
       "0  [{'time': -960, 'type': 'chatwheel', 'key': '1...      308   \n",
       "\n",
       "                                           cosmetics  dire_score  \\\n",
       "0  {'647': 130, '4670': 130, '4794': 4, '5181': 1...          42   \n",
       "\n",
       "   dire_team_id                                      draft_timings  duration  \\\n",
       "0          36.0  [{'order': 1, 'pick': False, 'active_team': 2,...      4934   \n",
       "\n",
       "   engine  first_blood_time  game_mode  human_players  leagueid  lobby_type  \\\n",
       "0       1                29          2             10     10749           1   \n",
       "\n",
       "   match_seq_num  negative_votes  \\\n",
       "0     4167421134             369   \n",
       "\n",
       "                                          objectives  \\\n",
       "0  [{'time': 29, 'type': 'CHAT_MESSAGE_FIRSTBLOOD...   \n",
       "\n",
       "                                          picks_bans  positive_votes  \\\n",
       "0  [{'is_pick': False, 'hero_id': 106, 'team': 1,...            4918   \n",
       "\n",
       "                                    radiant_gold_adv  radiant_score  \\\n",
       "0  [0, 495, 762, 808, 878, 1145, 2106, 2059, 2167...             54   \n",
       "\n",
       "   radiant_team_id  radiant_win  \\\n",
       "0             39.0         True   \n",
       "\n",
       "                                      radiant_xp_adv  skill  \\\n",
       "0  [0, 394, 247, 561, 224, 839, 1582, 1728, 1771,...    NaN   \n",
       "\n",
       "           start_time                                         teamfights  \\\n",
       "0 2019-08-15 11:20:48  [{'start': 915, 'end': 959, 'last_death': 944,...   \n",
       "\n",
       "   tower_status_dire  tower_status_radiant  version  replay_salt  series_id  \\\n",
       "0                  0                  1796       21     37509985     358264   \n",
       "\n",
       "   series_type                                             league  \\\n",
       "0            1  {'leagueid': 10749, 'ticket': None, 'banner': ...   \n",
       "\n",
       "                                        radiant_team  \\\n",
       "0  {'team_id': 39, 'name': 'Evil Geniuses', 'tag'...   \n",
       "\n",
       "                                           dire_team  \\\n",
       "0  {'team_id': 36, 'name': 'Natus Vincere', 'tag'...   \n",
       "\n",
       "                                             players  patch  \\\n",
       "0  [{'match_id': 4968150000, 'player_slot': 0, 'a...     41   \n",
       "\n",
       "                        all_word_counts my_word_counts   throw     loss  \\\n",
       "0  {'gl': 1, 'hf': 1, 'gg': 5, 'wp': 1}             {}  9155.0  18713.0   \n",
       "\n",
       "                                          replay_url  region  comeback  stomp  \n",
       "0  http://replay308.valve.net/570/4968150000_3750...     NaN       NaN    NaN  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data2 = pd.read_json('matches/league_id_10749_ti9_matchdata.json')\n",
    "#data2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   match_id         153 non-null    int64\n",
      " 1   duration         153 non-null    int64\n",
      " 2   leagueid         153 non-null    int64\n",
      " 3   match_seq_num    153 non-null    int64\n",
      " 4   series_id        153 non-null    int64\n",
      " 5   series_type      153 non-null    int64\n",
      " 6   patch            153 non-null    int64\n",
      " 7   dire_team_id     153 non-null    int64\n",
      " 8   radiant_team_id  153 non-null    int64\n",
      " 9   radiant_win      153 non-null    bool \n",
      "dtypes: bool(1), int64(9)\n",
      "memory usage: 11.0 KB\n"
     ]
    }
   ],
   "source": [
    "match_df = big_df[['match_id','duration', 'leagueid','match_seq_num','series_id', 'series_type', 'patch', 'dire_team_id', 'radiant_team_id', 'radiant_win' ]]\n",
    "match_df.info()\n",
    "#match_df.isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       match_id  radiant_win\n",
      "patch                       \n",
      "40          108          108\n",
      "41           45           45\n"
     ]
    }
   ],
   "source": [
    "groupedDF = match_df.filter(items=['match_id','radiant_win',\n",
    "                                          'patch'])  # Remove columns\n",
    "groupedDF = groupedDF.groupby(['patch']).count()  # Perform Aggregate\n",
    "print(groupedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = match_df[match_df.patch == 41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match_df.sort_values(by='match_id', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: load json file and normalize using pandas.json_normalize.\n",
    "\n",
    "** Dunno if there is any significant advantage to doing it one way or the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_struct = json.loads(data.to_json(orient=\"records\"))    \n",
    "#df_flat = pd.io.json.json_normalize(json_struct) #use pd.io.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning:\n",
      "\n",
      "pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "picks_df = json_normalize(data, 'picks_bans', max_level=0)\n",
    "#picks_df.head(100)\n",
    "#picks_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = picks_df[['match_id', 'order', 'is_pick', 'team', 'hero_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning:\n",
      "\n",
      "Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.astype(str)\n",
    "df = df.groupby('match_id')['is_pick','team','hero_id'].agg(' '.join)\n",
    "#df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new = df['order'].str.split(' ', expand=True)\n",
    "new1 = df['is_pick'].str.split(' ', expand=True)\n",
    "new2 = df['team'].str.split(' ', expand=True)\n",
    "new3 = df['hero_id'].str.split(' ', expand=True)\n",
    "#new1, new2, new3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column labels for the columns \n",
    "total_picks = 21 # recall range is 0-21 = 22 picks\n",
    "new1.columns = ['1is_pick', '2is_pick', '3is_pick', '4is_pick', '5is_pick', '6is_pick', '7is_pick','8is_pick','9is_pick','10is_pick','11is_pick','12is_pick','13is_pick','14is_pick','15is_pick','16is_pick','17is_pick','18is_pick','19is_pick','20is_pick','21is_pick', '22is_pick']\n",
    "new2.columns = ['1team', '2team', '3team', '4team', '5team', '6team', '7team', '8team', '9team', '10team', '11team', '12team', '13team', '14team', '15team', '16team', '17team', '18team', '19team', '20team', '21team', '22team']\n",
    "new3.columns = ['1hero_id', '2hero_id', '3hero_id', '4hero_id', '5hero_id', '6hero_id', '7hero_id', '8hero_id', '9hero_id', '10hero_id', '11hero_id', '12hero_id', '13hero_id', '14hero_id', '15hero_id', '16hero_id', '17hero_id', '18hero_id', '19hero_id', '20hero_id', '21hero_id',\n",
    "               '22hero_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = new1.join(new2).join(new3)\n",
    "#picks_df = new1.join(new2).join(new3)\n",
    "#picks_df.dtypes\n",
    "#picks_df.head(100)\n",
    "#data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick eyeball inspection to check if the draft information is preserved:\n",
    "\n",
    "\n",
    "Comparing match_id = 4888646940, we can see from above that the first pick (order=0) information was: \n",
    "- first pick (1ban): '4888646940\t0\tFalse\t1\t66'; w/c lines up with 1is_pick, 1hero_id, etc...\n",
    "- last pick: 9106\t4888646940\t21\tTrue\t0\t67; w/c lines up with 22is_pick, 22hero_id, etc...\n",
    "\n",
    "So, at least by a quick visual inspection, seems like the drafting data has been successfully cleaned. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing T/F values\n",
    "\n",
    "Convert T/F to boolean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://github.com/codexponent/dota2-draft-analysis/blob/master/draft-ml.ipynb\n",
    "# # # Converting boolean value into number\n",
    "boolean_values = 22\n",
    "for i in range(boolean_values):\n",
    "    pick_id = '{}is_pick'.format(i+1)\n",
    "    data[pick_id] = data[pick_id].apply(lambda x: 1 if x else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-organize columns according to prefix order:\n",
    "- pretty sure there's a better way to do this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks_df = data[['1is_pick', '1team', '1hero_id',\n",
    "               '2is_pick', '2team', '2hero_id', \n",
    "               '3is_pick', '3team', '3hero_id', \n",
    "               '4is_pick', '4team', '4hero_id', \n",
    "               '5is_pick', '5team', '5hero_id', \n",
    "               '6is_pick', '6team', '6hero_id', \n",
    "               '7is_pick', '7team', '7hero_id', \n",
    "               '8is_pick', '8team', '8hero_id', \n",
    "               '9is_pick', '9team', '9hero_id', \n",
    "               '10is_pick', '10team', '10hero_id', \n",
    "               '11is_pick', '11team', '11hero_id', \n",
    "               '12is_pick', '12team', '12hero_id',\n",
    "               '13is_pick', '13team', '13hero_id', \n",
    "               '14is_pick', '14team', '14hero_id', \n",
    "               '15is_pick', '15team', '15hero_id', \n",
    "               '16is_pick', '16team', '16hero_id', \n",
    "               '17is_pick', '17team', '17hero_id',\n",
    "               '18is_pick', '18team', '18hero_id', \n",
    "               '19is_pick', '19team', '19hero_id',\n",
    "               '20is_pick', '20team', '20hero_id',\n",
    "               '21is_pick', '21team', '21hero_id', \n",
    "                '22is_pick', '22team', '22hero_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks = picks_df\n",
    "#matchhistory = match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches2 = matches[['match_id', 'radiant_win']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks_clean = picks.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpicks = picks_clean.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-f77925460f1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#m = matches_df.copy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcommon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatches2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpicks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'match_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   7295\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7296\u001b[0m             \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7297\u001b[0;31m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7298\u001b[0m         )\n\u001b[1;32m   7299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# to avoid incompat dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0minferred_right\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minferred_left\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m                 ):\n\u001b[0;32m-> 1146\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m             \u001b[0;31m# datetimelikes must match exactly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "#p = picks_df[['match_id']] \n",
    "#m = matches_df.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picks dictionary\n",
    "picks_dict = {'match_id': int, '1is_pick': bool, '1team': bool, '1hero_id': int,\n",
    "               '2is_pick': bool, '2team': bool, '2hero_id': int, \n",
    "               '3is_pick': bool, '3team': bool, '3hero_id': int, \n",
    "               '4is_pick': bool, '4team': bool, '4hero_id': int, \n",
    "               '5is_pick': bool, '5team': bool, '5hero_id': int, \n",
    "               '6is_pick': bool, '6team': bool, '6hero_id': int, \n",
    "               '7is_pick': bool, '7team': bool, '7hero_id': int, \n",
    "               '8is_pick': bool, '8team': bool, '8hero_id': int, \n",
    "               '9is_pick': bool, '9team': bool, '9hero_id': int, \n",
    "               '10is_pick': bool, '10team':bool, '10hero_id': int, \n",
    "               '11is_pick': bool, '11team':bool, '11hero_id': int, \n",
    "               '12is_pick': bool, '12team':bool, '12hero_id': int,\n",
    "               '13is_pick': bool, '13team':bool, '13hero_id': int, \n",
    "               '14is_pick': bool, '14team':bool, '14hero_id': int, \n",
    "               '15is_pick': bool, '15team':bool, '15hero_id': int, \n",
    "               '16is_pick': bool, '16team':bool, '16hero_id': int, \n",
    "               '17is_pick': bool, '17team':bool, '17hero_id': int,\n",
    "               '18is_pick': bool, '18team':bool, '18hero_id': int, \n",
    "               '19is_pick': bool, '19team':bool, '19hero_id': int,\n",
    "               '20is_pick': bool, '20team':bool, '20hero_id': int,\n",
    "               '21is_pick': bool, '21team':bool, '21hero_id': int, \n",
    "                '22is_pick': bool, '22team':bool, '22hero_id': int}\n",
    "\n",
    "cpicks = cpicks.astype(picks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## picks_cleaned (44,68), and correct data types\n",
    "picks_cleaned = matches2.merge(cpicks, on=['match_id'])\n",
    "picks_cleaned.to_csv('starladder_picks_cleaned_merged.csv')\n",
    "matches.to_csv('starladder_matches_cleaned_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks.to_csv('data/starladder_picks.csv')\n",
    "matchhistory.to_csv('data/starladder_matchhistory.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'picks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-472b9a3a0daf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpicks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'picks' is not defined"
     ]
    }
   ],
   "source": [
    "picks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dbbd850d7c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpicks2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET-EM/EDA/opendota_matches/data/ti9_picks_cleaned.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "picks2 = pd.read_csv('GET-EM/EDA/opendota_matches/data/ti9_picks_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
